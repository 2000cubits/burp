(in no particular order)

* Make SSL_shutdown() work properly.

* Investigate HFS / resource forks and make support.

* Add include/exclude wildcards.

* Think about adding a utility to create certs, like easy-rsa from OpenVPN.
	(burp_ca has been added - does more need to be done?)

* Add acl/xattr support
	(generic linux and freebsd support is done - do solaris next)

* Improve the status monitor / counters.
	- Remember the phase1 scan counters so that later phases can have
	  things like estimated times.
	- Counters are missing from the logs when a backup is completed via
	  working dir recovery.
	- Can something be done to make key presses more responsive?

* Do not compress manifests and logs when compression is turned off.

* Allow random backups to be deleted safely when hardlinked_archive is on.

* Delete old backups by time.

* Delete old backups by space.

* Add an option to set hardlinked_archive on a cycle, instead of just being
  either on or off.

* Add the option to turn an existing hardlinked_archive (not 'current') into
  a non-hardlinked_archive, and vice versa. This could be useful for deleting
  backups out of the middle of a chain instead of just the oldest.

* Get metadata transfers to use librsync.

* Have an option to let the client give the server the encryption password
  and hence do server-side encryption. This would mean that network deltas
  with encryption can be done.

* Try to make backup_phase4_server more efficient. For example, a storage
  server using a CIFS mounted disk appears very slow when I have a backup
  containing 1,500,000 small files with very few changes.

* Investigate Windows 'bare metal restore'.

* Think about having a 'friendly' way of doing restores, as I have known some
  people to complain about having to type things on the command lne.

* Add 'working_dir_recovery_method = resume' option, which would continue a
  backup from the point it was interrupted.

* Add some kind of generic method for passing new fields from the client to
  the server, so that clients are less likely to have to upgrade.
  (can be added to the 'hello' line)

* Break the stupidly long find_files() function down into smaller pieces.
  (partly done)

* When a client is waiting a very long time on working directory recovery, it
  can get stuck in its select loop. Have some kind of a timeout. Or, go into
  a different kind of loop where it keeps trying to make a fresh connection.

* burp -a e: 'estimate' option - just run backup phase1 to find out roughly how 
  much space a client will use.

* Maybe look at the timer script regularly. If the time is now out of the
  defined range, interrupt the backup in such a way that it will pick up from
  where it left off the next time round.

* Make transfer_gzfile_in() and send_whole_file[_gz]() check checksums.

* Looks like the manifest.gz.tmp.tmp problem is back in working dir recovery.
